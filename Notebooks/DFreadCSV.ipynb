{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, BooleanType, ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Test4\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"D:\\\\LAB\\\\Spark\\\\test1.csv\")\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|      _c0|_c1|       _c2|   _c3|\n",
      "+---------+---+----------+------+\n",
      "|     Name|Age|Experience|Salary|\n",
      "|     Abhi| 26|         4| 30000|\n",
      "|    Oorja| 25|         2| 29000|\n",
      "|    Sagar| 25|         1| 65000|\n",
      "|   Chandi| 26|         4|   NaN|\n",
      "|    Amiya| 25|         4| 95000|\n",
      "|     Guru| 26|         4| 90000|\n",
      "|  Ansuman| 26|         5| 70000|\n",
      "|   Himesh| 26|         5| 98000|\n",
      "|  Sangram| 26|         5| 32000|\n",
      "|   Anukul| 25|         2| 28000|\n",
      "|   Sravya|NaN|         2| 29000|\n",
      "|Suryakant| 32|        10| 40000|\n",
      "|    Jyoti|NaN|         9|   NaN|\n",
      "|   Amrita| 35|        13|   NaN|\n",
      "|   Amrita|NaN|       NaN|   NaN|\n",
      "|      NaN| 33|        11| 58000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.read.format(\"csv\").load(\"D:\\\\LAB\\\\Spark\\\\test1.csv\")\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|      _c0|_c1|       _c2|   _c3|\n",
      "+---------+---+----------+------+\n",
      "|     Name|Age|Experience|Salary|\n",
      "|     Abhi| 26|         4| 30000|\n",
      "|    Oorja| 25|         2| 29000|\n",
      "|    Sagar| 25|         1| 65000|\n",
      "|   Chandi| 26|         4|   NaN|\n",
      "|    Amiya| 25|         4| 95000|\n",
      "|     Guru| 26|         4| 90000|\n",
      "|  Ansuman| 26|         5| 70000|\n",
      "|   Himesh| 26|         5| 98000|\n",
      "|  Sangram| 26|         5| 32000|\n",
      "|   Anukul| 25|         2| 28000|\n",
      "|   Sravya|NaN|         2| 29000|\n",
      "|Suryakant| 32|        10| 40000|\n",
      "|    Jyoti|NaN|         9|   NaN|\n",
      "|   Amrita| 35|        13|   NaN|\n",
      "|   Amrita|NaN|       NaN|   NaN|\n",
      "|      NaN| 33|        11| 58000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This code reads the data into DataFrame columns \"_c0\" for the first column and \"_c1\" for the second and so on. and by default data type for all these columns is treated as String."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Experience: string (nullable = true)\n",
      " |-- Salary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = spark.read.option(\"header\", True).csv(\"D:\\\\LAB\\\\Spark\\\\test1.csv\")\n",
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|Age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|     Abhi| 26|         4| 30000|\n",
      "|    Oorja| 25|         2| 29000|\n",
      "|    Sagar| 25|         1| 65000|\n",
      "|   Chandi| 26|         4|   NaN|\n",
      "|    Amiya| 25|         4| 95000|\n",
      "|     Guru| 26|         4| 90000|\n",
      "|  Ansuman| 26|         5| 70000|\n",
      "|   Himesh| 26|         5| 98000|\n",
      "|  Sangram| 26|         5| 32000|\n",
      "|   Anukul| 25|         2| 28000|\n",
      "|   Sravya|NaN|         2| 29000|\n",
      "|Suryakant| 32|        10| 40000|\n",
      "|    Jyoti|NaN|         9|   NaN|\n",
      "|   Amrita| 35|        13|   NaN|\n",
      "|   Amrita|NaN|       NaN|   NaN|\n",
      "|      NaN| 33|        11| 58000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = spark.read.options(inferSchema = \"True\", delimiter = \",\").csv(\"D:\\\\LAB\\\\Spark\\\\test1.csv\")\n",
    "\n",
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The default value of inferSchema is set to this option is False when setting to true it automatically infers column types based on the data. Note that, it requires reading the data one more time to infer the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#alternate way of writing above code\n",
    "df5 = spark.read.option(\"inferSchema\", True).option(\"delimiter\", \",\").csv(\"D:\\\\LAB\\\\Spark\\\\test1.csv\")\n",
    "df5.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Experience: double (nullable = true)\n",
      " |-- Salary: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6 = spark.read.options(header = \"True\", inferSchema = \"True\", delimiter = \",\").csv(\"D:\\\\LAB\\\\Spark\\\\test1.csv\")\n",
    "df6.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+-------+\n",
      "|     Name| Age|Experience| Salary|\n",
      "+---------+----+----------+-------+\n",
      "|     Abhi|26.0|       4.0|30000.0|\n",
      "|    Oorja|25.0|       2.0|29000.0|\n",
      "|    Sagar|25.0|       1.0|65000.0|\n",
      "|   Chandi|26.0|       4.0|    NaN|\n",
      "|    Amiya|25.0|       4.0|95000.0|\n",
      "|     Guru|26.0|       4.0|90000.0|\n",
      "|  Ansuman|26.0|       5.0|70000.0|\n",
      "|   Himesh|26.0|       5.0|98000.0|\n",
      "|  Sangram|26.0|       5.0|32000.0|\n",
      "|   Anukul|25.0|       2.0|28000.0|\n",
      "|   Sravya| NaN|       2.0|29000.0|\n",
      "|Suryakant|32.0|      10.0|40000.0|\n",
      "|    Jyoti| NaN|       9.0|    NaN|\n",
      "|   Amrita|35.0|      13.0|    NaN|\n",
      "|   Amrita| NaN|       NaN|    NaN|\n",
      "|      NaN|33.0|      11.0|58000.0|\n",
      "+---------+----+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If you know the schema of the file ahead and do not want to use the inferSchema option for column names and types, use user-defined custom column names and type using schema option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- RecordNumber: integer (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- ZipCodeType: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- LocationType: string (nullable = true)\n",
      " |-- Lat: double (nullable = true)\n",
      " |-- Long: double (nullable = true)\n",
      " |-- Xaxis: integer (nullable = true)\n",
      " |-- Yaxis: double (nullable = true)\n",
      " |-- Zaxis: double (nullable = true)\n",
      " |-- WorldRegion: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- LocationText: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Decommisioned: boolean (nullable = true)\n",
      " |-- TaxReturnsFiled: string (nullable = true)\n",
      " |-- EstimatedPopulation: integer (nullable = true)\n",
      " |-- TotalWages: integer (nullable = true)\n",
      " |-- Notes: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([StructField(\"RecordNumber\", IntegerType(), True),\\\n",
    "                   StructField(\"Zipcode\", IntegerType(), True),\\\n",
    "                   StructField(\"ZipCodeType\", StringType(), True),\\\n",
    "                   StructField(\"City\", StringType(), True),\\\n",
    "                   StructField(\"State\", StringType(), True),\\\n",
    "                   StructField(\"LocationType\", StringType(), True),\\\n",
    "                   StructField(\"Lat\", DoubleType(), True),\\\n",
    "                   StructField(\"Long\", DoubleType(), True),\\\n",
    "                   StructField(\"Xaxis\",IntegerType(),True),\\\n",
    "                   StructField(\"Yaxis\",DoubleType(),True),\\\n",
    "                   StructField(\"Zaxis\",DoubleType(),True),\\\n",
    "                   StructField(\"WorldRegion\",StringType(),True),\\\n",
    "                   StructField(\"Country\",StringType(),True),\\\n",
    "                   StructField(\"LocationText\",StringType(),True),\\\n",
    "                   StructField(\"Location\",StringType(),True),\\\n",
    "                   StructField(\"Decommisioned\",BooleanType(),True),\\\n",
    "                   StructField(\"TaxReturnsFiled\",StringType(),True),\\\n",
    "                   StructField(\"EstimatedPopulation\",IntegerType(),True),\\\n",
    "                   StructField(\"TotalWages\",IntegerType(),True),\\\n",
    "                   StructField(\"Notes\",StringType(),True)])\n",
    "\n",
    "df7 = spark.read.format('csv').option(\"header\", True).schema(schema).load(\"D:\\\\LAB\\\\Spark\\\\zipcodes-noheader.csv\")\n",
    "\n",
    "df7.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "|RecordNumber|Zipcode|ZipCodeType|               City|State|  LocationType|  Lat|   Long|Xaxis|Yaxis|Zaxis|WorldRegion|Country|        LocationText|            Location|Decommisioned|TaxReturnsFiled|EstimatedPopulation|TotalWages|        Notes|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "|           2|    704|   STANDARD|PASEO COSTA DEL SUR|   PR|NOT ACCEPTABLE|17.96| -66.22| null|-0.87|  0.3|         NA|     US|Paseo Costa Del S...|NA-US-PR-PASEO CO...|        false|           null|               null|      null|         null|\n",
      "|          10|    709|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14| -66.26| null|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        false|           null|               null|      null|         null|\n",
      "|       61391|  76166|     UNIQUE|  CINGULAR WIRELESS|   TX|NOT ACCEPTABLE|32.72| -97.31| null|-0.83| 0.54|         NA|     US|Cingular Wireless...|NA-US-TX-CINGULAR...|        false|           null|               null|      null|         null|\n",
      "|       61392|  76177|   STANDARD|         FORT WORTH|   TX|       PRIMARY|32.75| -97.33| null|-0.83| 0.54|         NA|     US|      Fort Worth, TX| NA-US-TX-FORT WORTH|        false|           2126|               4053| 122396986|         null|\n",
      "|       61393|  76177|   STANDARD|           FT WORTH|   TX|    ACCEPTABLE|32.75| -97.33| null|-0.83| 0.54|         NA|     US|        Ft Worth, TX|   NA-US-TX-FT WORTH|        false|           2126|               4053| 122396986|         null|\n",
      "|           4|    704|   STANDARD|    URB EUGENE RICE|   PR|NOT ACCEPTABLE|17.96| -66.22| null|-0.87|  0.3|         NA|     US| Urb Eugene Rice, PR|NA-US-PR-URB EUGE...|        false|           null|               null|      null|         null|\n",
      "|       39827|  85209|   STANDARD|               MESA|   AZ|       PRIMARY|33.37|-111.64| null|-0.77| 0.55|         NA|     US|            Mesa, AZ|       NA-US-AZ-MESA|        false|          14962|              26883| 563792730|no NWS data, |\n",
      "|       39828|  85210|   STANDARD|               MESA|   AZ|       PRIMARY|33.38|-111.84| null|-0.77| 0.55|         NA|     US|            Mesa, AZ|       NA-US-AZ-MESA|        false|          14374|              25446| 471000465|         null|\n",
      "|       49345|  32046|   STANDARD|           HILLIARD|   FL|       PRIMARY|30.69| -81.92| null|-0.85| 0.51|         NA|     US|        Hilliard, FL|   NA-US-FL-HILLIARD|        false|           3922|               7443| 133112149|         null|\n",
      "|       49346|  34445|     PO BOX|             HOLDER|   FL|       PRIMARY|28.96| -82.41| null|-0.86| 0.48|         NA|     US|          Holder, FL|     NA-US-FL-HOLDER|        false|           null|               null|      null|         null|\n",
      "|       49347|  32564|   STANDARD|               HOLT|   FL|       PRIMARY|30.72| -86.67| null|-0.85| 0.51|         NA|     US|            Holt, FL|       NA-US-FL-HOLT|        false|           1207|               2190|  36395913|         null|\n",
      "|       49348|  34487|     PO BOX|          HOMOSASSA|   FL|       PRIMARY|28.78| -82.61| null|-0.86| 0.48|         NA|     US|       Homosassa, FL|  NA-US-FL-HOMOSASSA|        false|           null|               null|      null|         null|\n",
      "|          10|    708|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14| -66.26| null|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        false|           null|               null|      null|         null|\n",
      "|           3|    704|   STANDARD|      SECT LANAUSSE|   PR|NOT ACCEPTABLE|17.96| -66.22| null|-0.87|  0.3|         NA|     US|   Sect Lanausse, PR|NA-US-PR-SECT LAN...|        false|           null|               null|      null|         null|\n",
      "|       54354|  36275|     PO BOX|      SPRING GARDEN|   AL|       PRIMARY|33.97| -85.55| null|-0.82| 0.55|         NA|     US|   Spring Garden, AL|NA-US-AL-SPRING G...|        false|           null|               null|      null|         null|\n",
      "|       54355|  35146|   STANDARD|        SPRINGVILLE|   AL|       PRIMARY|33.77| -86.47| null|-0.82| 0.55|         NA|     US|     Springville, AL|NA-US-AL-SPRINGVILLE|        false|           4046|               7845| 172127599|         null|\n",
      "|       54356|  35585|   STANDARD|        SPRUCE PINE|   AL|       PRIMARY|34.37| -87.69| null|-0.82| 0.56|         NA|     US|     Spruce Pine, AL|NA-US-AL-SPRUCE PINE|        false|            610|               1209|  18525517|         null|\n",
      "|       76511|  27007|   STANDARD|           ASH HILL|   NC|NOT ACCEPTABLE| 36.4| -80.56| null|-0.79| 0.59|         NA|     US|        Ash Hill, NC|   NA-US-NC-ASH HILL|        false|            842|               1666|  28876493|         null|\n",
      "|       76512|  27203|   STANDARD|           ASHEBORO|   NC|       PRIMARY|35.71| -79.81| null|-0.79| 0.58|         NA|     US|        Asheboro, NC|   NA-US-NC-ASHEBORO|        false|           8355|              15228| 215474318|         null|\n",
      "|       76513|  27204|     PO BOX|           ASHEBORO|   NC|       PRIMARY|35.71| -79.81| null|-0.79| 0.58|         NA|     US|        Asheboro, NC|   NA-US-NC-ASHEBORO|        false|           1035|               1816|  30322473|         null|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- RecordNumber: integer (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- ZipCodeType: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- LocationType: string (nullable = true)\n",
      " |-- Lat: double (nullable = true)\n",
      " |-- Long: double (nullable = true)\n",
      " |-- Xaxis: integer (nullable = true)\n",
      " |-- Yaxis: double (nullable = true)\n",
      " |-- Zaxis: double (nullable = true)\n",
      " |-- WorldRegion: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- LocationText: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Decommisioned: boolean (nullable = true)\n",
      " |-- TaxReturnsFiled: string (nullable = true)\n",
      " |-- EstimatedPopulation: integer (nullable = true)\n",
      " |-- TotalWages: integer (nullable = true)\n",
      " |-- Notes: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema2 = StructType() \\\n",
    "      .add(\"RecordNumber\",IntegerType(),True) \\\n",
    "      .add(\"Zipcode\",IntegerType(),True) \\\n",
    "      .add(\"ZipCodeType\",StringType(),True) \\\n",
    "      .add(\"City\",StringType(),True) \\\n",
    "      .add(\"State\",StringType(),True) \\\n",
    "      .add(\"LocationType\",StringType(),True) \\\n",
    "      .add(\"Lat\",DoubleType(),True) \\\n",
    "      .add(\"Long\",DoubleType(),True) \\\n",
    "      .add(\"Xaxis\",IntegerType(),True) \\\n",
    "      .add(\"Yaxis\",DoubleType(),True) \\\n",
    "      .add(\"Zaxis\",DoubleType(),True) \\\n",
    "      .add(\"WorldRegion\",StringType(),True) \\\n",
    "      .add(\"Country\",StringType(),True) \\\n",
    "      .add(\"LocationText\",StringType(),True) \\\n",
    "      .add(\"Location\",StringType(),True) \\\n",
    "      .add(\"Decommisioned\",BooleanType(),True) \\\n",
    "      .add(\"TaxReturnsFiled\",StringType(),True) \\\n",
    "      .add(\"EstimatedPopulation\",IntegerType(),True) \\\n",
    "      .add(\"TotalWages\",IntegerType(),True) \\\n",
    "      .add(\"Notes\",StringType(),True)\n",
    "\n",
    "df8 = spark.read.format(\"csv\").option(\"header\", True).schema(schema2).load(\"D:\\\\LAB\\\\Spark\\\\zipcodes-noheader.csv\")\n",
    "\n",
    "df8.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "|RecordNumber|Zipcode|ZipCodeType|               City|State|  LocationType|  Lat|   Long|Xaxis|Yaxis|Zaxis|WorldRegion|Country|        LocationText|            Location|Decommisioned|TaxReturnsFiled|EstimatedPopulation|TotalWages|        Notes|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "|           2|    704|   STANDARD|PASEO COSTA DEL SUR|   PR|NOT ACCEPTABLE|17.96| -66.22| null|-0.87|  0.3|         NA|     US|Paseo Costa Del S...|NA-US-PR-PASEO CO...|        false|           null|               null|      null|         null|\n",
      "|          10|    709|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14| -66.26| null|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        false|           null|               null|      null|         null|\n",
      "|       61391|  76166|     UNIQUE|  CINGULAR WIRELESS|   TX|NOT ACCEPTABLE|32.72| -97.31| null|-0.83| 0.54|         NA|     US|Cingular Wireless...|NA-US-TX-CINGULAR...|        false|           null|               null|      null|         null|\n",
      "|       61392|  76177|   STANDARD|         FORT WORTH|   TX|       PRIMARY|32.75| -97.33| null|-0.83| 0.54|         NA|     US|      Fort Worth, TX| NA-US-TX-FORT WORTH|        false|           2126|               4053| 122396986|         null|\n",
      "|       61393|  76177|   STANDARD|           FT WORTH|   TX|    ACCEPTABLE|32.75| -97.33| null|-0.83| 0.54|         NA|     US|        Ft Worth, TX|   NA-US-TX-FT WORTH|        false|           2126|               4053| 122396986|         null|\n",
      "|           4|    704|   STANDARD|    URB EUGENE RICE|   PR|NOT ACCEPTABLE|17.96| -66.22| null|-0.87|  0.3|         NA|     US| Urb Eugene Rice, PR|NA-US-PR-URB EUGE...|        false|           null|               null|      null|         null|\n",
      "|       39827|  85209|   STANDARD|               MESA|   AZ|       PRIMARY|33.37|-111.64| null|-0.77| 0.55|         NA|     US|            Mesa, AZ|       NA-US-AZ-MESA|        false|          14962|              26883| 563792730|no NWS data, |\n",
      "|       39828|  85210|   STANDARD|               MESA|   AZ|       PRIMARY|33.38|-111.84| null|-0.77| 0.55|         NA|     US|            Mesa, AZ|       NA-US-AZ-MESA|        false|          14374|              25446| 471000465|         null|\n",
      "|       49345|  32046|   STANDARD|           HILLIARD|   FL|       PRIMARY|30.69| -81.92| null|-0.85| 0.51|         NA|     US|        Hilliard, FL|   NA-US-FL-HILLIARD|        false|           3922|               7443| 133112149|         null|\n",
      "|       49346|  34445|     PO BOX|             HOLDER|   FL|       PRIMARY|28.96| -82.41| null|-0.86| 0.48|         NA|     US|          Holder, FL|     NA-US-FL-HOLDER|        false|           null|               null|      null|         null|\n",
      "|       49347|  32564|   STANDARD|               HOLT|   FL|       PRIMARY|30.72| -86.67| null|-0.85| 0.51|         NA|     US|            Holt, FL|       NA-US-FL-HOLT|        false|           1207|               2190|  36395913|         null|\n",
      "|       49348|  34487|     PO BOX|          HOMOSASSA|   FL|       PRIMARY|28.78| -82.61| null|-0.86| 0.48|         NA|     US|       Homosassa, FL|  NA-US-FL-HOMOSASSA|        false|           null|               null|      null|         null|\n",
      "|          10|    708|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14| -66.26| null|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        false|           null|               null|      null|         null|\n",
      "|           3|    704|   STANDARD|      SECT LANAUSSE|   PR|NOT ACCEPTABLE|17.96| -66.22| null|-0.87|  0.3|         NA|     US|   Sect Lanausse, PR|NA-US-PR-SECT LAN...|        false|           null|               null|      null|         null|\n",
      "|       54354|  36275|     PO BOX|      SPRING GARDEN|   AL|       PRIMARY|33.97| -85.55| null|-0.82| 0.55|         NA|     US|   Spring Garden, AL|NA-US-AL-SPRING G...|        false|           null|               null|      null|         null|\n",
      "|       54355|  35146|   STANDARD|        SPRINGVILLE|   AL|       PRIMARY|33.77| -86.47| null|-0.82| 0.55|         NA|     US|     Springville, AL|NA-US-AL-SPRINGVILLE|        false|           4046|               7845| 172127599|         null|\n",
      "|       54356|  35585|   STANDARD|        SPRUCE PINE|   AL|       PRIMARY|34.37| -87.69| null|-0.82| 0.56|         NA|     US|     Spruce Pine, AL|NA-US-AL-SPRUCE PINE|        false|            610|               1209|  18525517|         null|\n",
      "|       76511|  27007|   STANDARD|           ASH HILL|   NC|NOT ACCEPTABLE| 36.4| -80.56| null|-0.79| 0.59|         NA|     US|        Ash Hill, NC|   NA-US-NC-ASH HILL|        false|            842|               1666|  28876493|         null|\n",
      "|       76512|  27203|   STANDARD|           ASHEBORO|   NC|       PRIMARY|35.71| -79.81| null|-0.79| 0.58|         NA|     US|        Asheboro, NC|   NA-US-NC-ASHEBORO|        false|           8355|              15228| 215474318|         null|\n",
      "|       76513|  27204|     PO BOX|           ASHEBORO|   NC|       PRIMARY|35.71| -79.81| null|-0.79| 0.58|         NA|     US|        Asheboro, NC|   NA-US-NC-ASHEBORO|        false|           1035|               1816|  30322473|         null|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df8.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a temporary view on CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing data from DataFrame to csv file\n",
    "df6.write.option(\"header\", True).mode(\"overwrite\").csv(\"D:/LAB/Spark/jupyter_notebooks/Output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+-------+\n",
      "|      _c0| _c1|       _c2|    _c3|\n",
      "+---------+----+----------+-------+\n",
      "|     Name| Age|Experience| Salary|\n",
      "|     Abhi|26.0|       4.0|30000.0|\n",
      "|    Oorja|25.0|       2.0|29000.0|\n",
      "|    Sagar|25.0|       1.0|65000.0|\n",
      "|   Chandi|26.0|       4.0|    NaN|\n",
      "|    Amiya|25.0|       4.0|95000.0|\n",
      "|     Guru|26.0|       4.0|90000.0|\n",
      "|  Ansuman|26.0|       5.0|70000.0|\n",
      "|   Himesh|26.0|       5.0|98000.0|\n",
      "|  Sangram|26.0|       5.0|32000.0|\n",
      "|   Anukul|25.0|       2.0|28000.0|\n",
      "|   Sravya| NaN|       2.0|29000.0|\n",
      "|Suryakant|32.0|      10.0|40000.0|\n",
      "|    Jyoti| NaN|       9.0|    NaN|\n",
      "|   Amrita|35.0|      13.0|    NaN|\n",
      "|   Amrita| NaN|       NaN|    NaN|\n",
      "|      NaN|33.0|      11.0|58000.0|\n",
      "+---------+----+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"create temporary view employee using csv options (path \\'D:/LAB/Spark/jupyter_notebooks/Output/employee.csv')\")\n",
    "spark.sql(\"select * from employee\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a temporary view on Partitioned CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.write.partitionBy(\"Experience\", \"Salary\").mode(\"overwrite\").csv(\"D:/LAB/Spark/jupyter_notebooks/Output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-------+\n",
      "|   _c0| _c1| Salary|\n",
      "+------+----+-------+\n",
      "|Chandi|26.0|    NaN|\n",
      "| Amiya|25.0|95000.0|\n",
      "|  Abhi|26.0|30000.0|\n",
      "|  Guru|26.0|90000.0|\n",
      "+------+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"create temporary view employee using csv options (path \\'D:/LAB/Spark/jupyter_notebooks/Output/Experience=4.0')\")\n",
    "spark.sql(\"select * from employee\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
